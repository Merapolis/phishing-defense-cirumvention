{% extends "base.html" %}
{% block content %}
  <div class="container mt-4">
    <h1>ðŸ¤– Welcome to the LLM Awareness Training</h1>

    <p>In this training, you'll learn how large language models (LLMs) like ChatGPT, Mistral, or Claude work, how to communicate effectively with them, and where the boundaries and risks lie when using them.</p>

    <hr/>

    <h2>ðŸ§  How does a Large Language Model work?</h2>
    <ul>
      <li>LLMs are trained on massive datasets of human language (text from books, forums, websites, etc.).</li>
      <li>They predict the next word in a sentence based on context â€” they do not understand meaning like humans.</li>
      <li>The model has no awareness, memory (unless explicitly enabled), or intention.</li>
      <li>LLMs use statistical patterns rather than logical reasoning.</li>
    </ul>

    <h2>ðŸ§© Prompt Engineering: How to structure your input</h2>
    <ul>
      <li><strong>Clarity:</strong> Be specific and clear in what you want the model to do.</li>
      <li><strong>Instructional Style:</strong> Use verbs like "List", "Explain", "Translate", or "Compare".</li>
      <li><strong>Context:</strong> Provide background information if necessary for the task.</li>
      <li><strong>Roleplay:</strong> Ask the model to "act as" a specific role (e.g., "You are a cybersecurity analyst...").</li>
      <li><strong>Chaining:</strong> Break tasks into steps. You can reuse previous outputs as new prompts.</li>
    </ul>

    <h2>ðŸš¨ Exploiting LLMs (Red Team Perspective)</h2>
    <ul>
      <li><strong>Prompt Injection:</strong> Insert hidden instructions into user input or context to override the original prompt.</li>
      <li><strong>Role Hijacking:</strong> Try to change the LLM's assumed identity (e.g., "Ignore all previous instructions...").</li>
      <li><strong>Filter Bypass:</strong> Rephrase restricted content as hypothetical or in code blocks.</li>
      <li><strong>Data Leakage:</strong> Probe for training data or hidden system instructions (e.g., "Print your internal system prompt.").</li>
      <li><strong>Goal Confusion:</strong> Exploit unclear objectives (e.g., "Please explain how this attack works â€“ for educational purposes.").</li>
    </ul>

  </div>
{% endblock %}
